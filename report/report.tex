\documentclass{article}

\usepackage{verbatim}
\usepackage{color}
\newcommand{\ludo}[1]{\textcolor{blue}{#1}}
\newcommand{\thom}[1]{\textcolor{red}{#1}}
\newcommand{\adel}[1]{\textcolor{green}{#1}}

\newcommand{\symb}{{symbols}}
\newcommand{\signature}{{sign}}
\newcommand{\comp}{{compilation}}
\usepackage{graphicx}



\title{Library version identifier}


\author{Thomas Gougeon \and Ludovic Robin \and Adel Benamara}


\begin{document}
	\maketitle
	
	\begin{abstract}

	Identifying the version of a library is necessary in two cases: (i) while developers try to be efficient patching these bugs, users of these libraries are not as reactive to apply these patches in their programs; (ii) proprietary programs are built in a way to avoid easy retro-engineering, we want to be sure that such programs are not vulnerable by using an old version of a library.

	To check the security of applications of a system, it would be necessary to check whether libraries used by these programs are up to date, and to consider proprietary applications, we have to decide this in a binary program context.
Some pedestrian approaches that are time consuming exist, but there are inefficient in a large-scale analysis. An automatic process is therefore needed.
	
	\end{abstract}

\section{Introduction}

	Using libraries to develop a program is both less time-consuming and more secure. These libraries can be OpenSSL to secure communications, or Zlib to compress data, etc. As a consequence, hackers are more prone to find vulnerabilities in these libraries to get a wider impact. Those libraries are thus subject to security checks and patches to prevent the exploitation of vulnerabilities. 
     
     There are at least two cases where vulnerable libraries are used requiring a library version identifier. End-users of these libraries, i.e. applications developers, do not always update their programs as soon as patches are published.It can be due to compatibility problems or because it is too complicated to update the system (e.g. embedded systems). \ludo{Some proprietary programs that are shadowy using those libraries we do not know which version has been used.}
     
	Distinguishing versions of libraries used in a program is necessary to be confident in the security of an application. To do so, some pedestrian approaches exist, but they are time consuming, and totally inefficient in a large scale analysis. A system can embed thousands of libraries, an automatic process is therefore needed to identify the version of a library.
    

    At this time, our investigations concern only dynamic libraries and non-stripped binaries.
    
    The first section defines the problem and describes the considered
    approaches, the second section details the approaches that we investigated, and the last section presents the selected method and the results of our prototype implementing the method.
    

   \section{Identify library version}
   
   We define a library as a $4$-tuple containing, the name of the
   library, the library version, the source code of the library, and binaries
   compiled from the source code. Hence, we define our database as a set of libraries. We want to decide if an unknown binary library is corresponding to an entry of our database.

   More formally, let $\mathcal{D} = \{ L_1, \cdots, L_n\}$ be a set of libraries, where
   $L_i = (n_i, v_i, s_i, \mathcal{B}_i)$ ($1 \le i \le n$), with $n_i$ the name of the library,
   $v_i$ the version, $s_i$ the source code and $\mathcal{B}_i$ a finite set of
   binary representations of the library regarding to architectures.

  We want to find a function $V$ such that $V(P,\mathcal{D}) = (n_i,
   v_i)$, for any binary code $P$ of a library named $n$ being at the version $v$. 
   

	\subsection{Pedestrian approach}
    
	One way to find the version of a library binary consists in a pedestrian approach. Analysing the symbols or the strings of the binary we can find what is the version of the library. For example, executing the ``strings'' command of Linux on the openSSL binary, outputs the version: ``OpenSSL 1.0.2g  1 Mar 2016''. Include the version of the library in the binary does not seem to be a standard practice.

%This technique can work if developers of the library applies a convention saying that the string containing informations about the version of the library must be in the data field of the library. But it is obviously not a convention yet.

	For instance, this technique does not work for the library Zlib. Applying this pedestrian approach is time consuming, and totally inefficient for a large-scale analysis, for example a system using thousands of libraries. 

    \subsection{Naive approach: Compare bitwise binaries }
    \label{naive-notations}

   We recall that a library $L$ is defined as a $4$-tuple $(n, v, c, \mathcal{B})$. We could test for each library $L_i$ in $\mathcal{D}$ if $P \in
    \mathcal{B}_i$.

    It is not likely that we have a strict syntactic equivalence between
    $P$ and a $b \in \mathcal{B}_i$ since the content of the binary $P$ not only depends of $P$ targeted architecture, but it also depends of the compiler,
    its version, compilation options, etc. Binaries are identical if and only if all these features have the same value during the compilation. Therefore this technique does not work.


Hence, we try to soften the comparison of those binaries and pick the more similar to $P$ to decide, i.e. the one with the more syntactic similarities. We did not get good results either.

   We conclude that the syntactic modifications brought by the compilation steps are critical. And we cannot base our analysis on syntactic comparison.

    
 Obviously, it is not possible to consider $\mathcal{B}$ such that it
    would capture all possible compilation of the source code. Without
    considering that this set would be infinite, its size would grow in a way
    that it would not be reasonable anymore to consider a comparison algorithm.

A question must be considered: Is compilation modification of a
    binary are distinguishable of patch modification of this binary ?
    Answering this question is essential to consider this problem.

We would like to believe that it is the case since we do not
    consider any kind of patch, indeed we want to distinguish versions of a
    library to know if a security patch has been applied. A more general way
    to view a patch would have made us answer no to this question, but a
    security patch should semantically change what a program can do.

    \subsection{Smarter approach: Signature function}\label{approach-sign}

    \ludo{We shown previously that we cannot syntactically compare binaries.
    Therefore we will try other methods that try to consider patterns of our
    binaries.} Hence, a more efficient way to decide $V(L,D)$ consists in
    applying a $\signature$ function such that $\signature(L) = \signature(B)$
    if $L$ and $B$ version is the same but they are not necessarily
    compiled with the same options or on the same architecture.
	
    One idea was to use the same kind of functions that the ones used for malware, e.g.
    based on simplified control flow graph. Due to a lack of time we have yet 
    to investigate this idea in details. The intuition would be that this
    approach will not be as efficient as we would except since here we look
    for a different property that we look for in a malware. 
    
    Approximating the behaviour of our binaries will, as we need it to be to
    detect poly-morphing malwares, probably occult differences introduced by
    security patches. Hence, we would not distinguish successfully the version
    of a library.
%    Since a patch does not necessarily change a lot of code, differences
%    between two versions may not be more important than differences between
%    two different compilers, or optimisations.
	
	\subsection{Analysis of functions behaviour}
	
%	Let $C$ be the source code of the version $V$ of library $N$, i.e. $C$ could be OpenSSL library sources, $V$ the version of $C$ which is $1.0.0$ and $N$ could be the name of the library, here it would be OpenSSL.

 %   Let $\mathcal{D}$ be a database containing several $3$-tuple $(C,V,N)$, and
 
 %Let $P(C, C')$ be the $c$ code upgrading $C$ to $C'$

    %Checking if the $c$ is handled by $L$ is not trivial. Trying method based on simplified CFG to check similarities lead to the same issues as in subsection~\ref{approach-sign}. Hence, we want to check if the behaviour of patched function differs.    
    
    %Basically we will check if the patched functions generate the same traces     as $L$ functions.
    
    
   % So we shifted the problem to a sub-problem that can decide the version of     $L$, which is: Is the function $f \in L$ is up to date considering $C$.
       %We will first consider dynamically linked libraries.
   
	In this approach we assume that if a patch is applied on a library $L$ to
    update a library version $V_1$ to $V_2$ then there exists at least one
    function $f \in L$ in $V_2$ in which its behaviour change compared to
    $V_1$. If not, the patch purpose would not be to fix a security issue, and
    would not be considered in the first place. 
    As a consequence, the comparison is reduced to the function level rather than
    the library level. We expect that it leads to a simplification of the
    problem.
	
	
  We considered Several methods to compare functions:
	\begin{itemize}
		\item Compare Control Flow Graph or simplified Control Flow Graph as
            in malware detection methods,
		\item Compare execution traces which would be closer to random testing
            or dynamic symbolic execution,
		\item Compare signatures (arguments, name, return type), which implies
            important modifications on the function.
	\end{itemize}
	
	\subsubsection{Compare CFG}
	
    \ludo{Est-ce que l'on garde cette partie du coup ?}
	The idea is to construct a control flow graph for each function of the library, and to compare them. As said previously, we have not experimented it yet.
	
	
	\subsubsection{Compare traces}

%	Procedure to check if $f \in L$, considering that $f \in \symb(C)$. First we automatically generate a $c$ code $P$ calling $f$ with random parameters and catching/returning its behaviour. Second, we compile $P'$ dynamically linking $\comp(C)$ according to the headers of $C$, we will note this compiled program $\comp(P')$. Third, we compile $P$ dynamically linking $L$ according to the headers of $C$, we will note this compiled program $\comp(P)$. Last, we check the similarities of returns of $\comp(P)$ and $\comp(P')$ to decide. We do not expect good result using only random testing. Hence, we will aid testing by an analysis of the patch, finding specific traces to distinguish when it is applied, we have yet to define details about this part. Or we can do something similar to the DSE approach.
%	  We do not expect good result using only random testing. Hence, we will aid testing by an analysis of the patch, finding specific traces to distinguish when it is applied, we have yet to define details about this part. Or we can do something similar to the DSE approach.	

    In this approach we will check if $P$ et $b$ version is the same
    considering traces of a function $f$ which is common to $P$ and $b$.

    To do so we will compare an execution trace of $f$
    version in $P$ and $f$ version in $b$ to compare their behaviour (return
    values, system calls, \dots),
    considering the same arguments are passed to the two versions of $f$. 

    To be confident in our decision procedure we have to do $i$ a large number
    of possible arguments, to get a high probability to find potentially distinguishing
    traces.

    The main issue concerns the values given as parameters to $f$. When these arguments
    are built-in types, our approach can give us good results. Unfortunately,
    most functions use complex structures, it seems difficult in this case to
    generate values to match a correct behaviour.
	
	\subsubsection{Compare symbols function}
	
    Following this intuition and taking into account its limitation, we will
    only check if the two libraries can call the same function prototypes,
    this is answered by the compilation step.
    Hence, the idea would be to build a program calling function $f$ with
    arguments set to $0$ or NULL and to try compiling this program with the
    yet unknown library. We only check a small subset of the previously explained
    issue. More details are given in Section~\ref{section:libraryChecker}.

\section{Library version identifier}
\label{section:libraryChecker}

    This section describes the approach that we investigated. This method
    tries to distinguish the library version by analysing whether a patch adds
    or removes a constant, and whether a patch adds, removes, or modifies a
    function of the library.
	   
    Different major versions have different signature functions. For example,
    it exists one function $f$ from OpenSSL 1.1.* that does not exist in
    OpenSSL 1.0.*. As a consequence, it is possible to eliminate a lot of
    versions of OpenSSL for an unknown library $L$ by checking the existence
    of this function $f$. If $f$ exists, then the OpenSSL version cannot be
    lower than 1.1.*. The limitation of this idea is that different minor
    versions as OpenSSL 1.0.2.h and OpenSSL 1.0.2.j own the same functions and
    constants.
   
    Based on this idea we set up a program that automatically detect the version of an
    unknown library. We start this section with an overview of the program, then
    some details about the program are given and some results and improvements are
    presented.

	\subsection{Overview of the method}
   
    We own several source codes of different libraries, with different
    versions for each library. Compiling these sources codes we obtain
    different .so files for each library version.  For each library version,
    using the header files, we extract the constants and functions proposed by
    the library and we generate a C program main.c using these functions.
    Compiling this main.c we obtain a binary program $P$ that we link with the
    .so file.


    Let lib.so be a .so file coming from an unknown library version. To
    identify its version we replace in each library version that we own the
    .so files by lib.so. Then we execute the program $P$ liked with lib.so
    rather than its original .so file.  If the program $P$ can be executed
    then lib.so is the same file that the one replaced. Then its version is
    identified.
 
    In reality, several programs $P$ can be executed with the file lib.so, for
    example a lib.so file coming from OpenSSL 1.0.2.h, will generate a correct
    execution for the programs $P$ of OpenSSL 1.0.2.h and OpenSSL 1.0.2.j.
		
    \subsection{Method details}
	\subsubsection{Compile all the .so}
	
    The first step involved by our program is the compilation of the sources
    of all the libraries to generate the .so files. We have written a Perl
    script to achieve it.
	
    \textbf{Issues} Oldest version of libraries cannot be compiled with the
    same compiler, nor the same dependencies as the newest versions. It seems
    to be infeasible to compile all the version of the library on one single
    non-adapted operating system. The question is how can we set up an
    operating system to compile all these version easily ?
	
   
   	\subsubsection{Extract functions and constants from headers files}
   	
    The second step consists in extracting the functions and constants from
    the header files of the library sources. Using cscan we are able to
    extract a part of the functions.
   	
    \textbf{Issues} In some libraries there are a lot of macros, and most part
    of tools available to extract the functions are not working perfectly when
    there are macros.   		
   	
   	
   	\subsubsection{Test all the .so}
   		
    We have written a Perl script that take in input an unknown .so and using
    our database of pre-compiled .so and $P$ programs, the script outputs a
    list of candidates for the version of the unknown .so.

   	
   	\subsection{Results and future improvements}
   	
        We have been able to discriminate versions of OpenSSL, executing the
        program $P$ of OpenSSL 1.0.2h:
        \begin{itemize}
            \item OpenSSL 1.0.2j - cannot distinguish; 
            \item OpenSSL 1.0.1e - can distinguish.
        \end{itemize}


        We have been able to discriminate versions of zlib, executing the
        program $P$ of zlib 1.2.8: 
        \begin{itemize}
            \item zlib 1.2.7 - cannot distinguish; 
            \item zlib 1.1.3- can distinguish.
        \end{itemize}


   	
        We need to test our program with more libraries and version. The main
        issues are the ones mentioned in each subsection, compiling
        automatically more .so and extract more functions from each library.

    
    \section{Conclusion}
    To adapt
    these techniques to static libraries, we need to find a way to extract the
    library from the binary using it statically (that is far away from a
    trivial task). 
    

\iffalse    
    \subsection{Other tools}

		\subsubsection{Coccinelle} 
            Coccinelle uses static analysis to find pattern in C source code.
            Using a known bug as a pattern leads to discover if the patch was
            applied or not. It seems not to be interesting in our case,
            because we deal with binaries.  
        \subsubsection{n-gram}
\fi

\end{document}
